---
title: "[Paper Review] Qwen2.5"
date: 2025-2-4
author: jieun
math: True
categories: [Language-Model]
tags: [LLM, Qwen]
typora-root-url: ..
---

Qwen은 알리바바 클라우드에서 개발한 LLM입니다.

![](/assets/img/llm/qwen1.png)

## 1. 모델 구조

### Dense Transformer

### Dense Transformer + MoE

![](/assets/img/llm/MoE.png)

## 2. 모델 성능



## Reference

- [LLM 아키텍처에 Mixture of Experts(MoE)를 활용하기](https://developer.nvidia.com/ko-kr/blog/applying-mixture-of-experts-in-llm-architectures/)

- [Mixture-of-Experts with Expert Choice Routing](https://research.google/blog/mixture-of-experts-with-expert-choice-routing/)
- Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity