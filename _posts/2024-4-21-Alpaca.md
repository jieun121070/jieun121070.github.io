---
title: "[Paper Review] Alpaca: A Strong, Replicable Instruction-Following Model"
date: 2024-4-21
author: jieun
math: True
categories: [Language-Model]
tags: [LLM, sLLM, Llama, Alpaca]
typora-root-url: ..
---

오늘 소개할 [**Alpaca**](https://crfm.stanford.edu/2023/03/13/alpaca.html)는 Stanford에서 LLaMA 7B를 기반으로 만든 파생 모델입니다. LLaMA 자체는 단순 언어 모델인데, LLaMA에 instruction tuning을 거쳐 나온 모델이 바로 Alpaca입니다. instruction tuning은 모델이 사용자의 지시문을 이해하고, 그 지시에 맞춰 작업을 수행하도록 학습시키는 과정을 의미하는데요. instruction tuning을 위해서는 아래와 같이 지시문과 출력으로 이루어진 데이터가 필요합니다. 

> Instruction: Translate the sentence "I love machine learning" to French.  
> Output: J'aime l'apprentissage automatique.

Alpaca는 이러한 instruction data를 GPT-3.5 API를 사용해 아주 저렴하게 만드는 방법을 보여주었다는 점에서 큰 의미를 갖는 모델입니다. Alpaca의 모델 구조와 instruction data를 만든 과정을 좀 더 자세히 살펴보겠습니다.

## 등장 배경

많은 유저들이 일상 생활 속에서 ChatGPT와 같은 instruction-following 모델들을 사용하고 있지만, 여전히 해결되지 못한 문제들이 남아있습니다. 거짓 정보를 만들어내거나 사회적 고정관념을 퍼뜨리거나, 유해한 언어를 생성하는 등의 문제들 입니다. 이를 해결하기 위해 학계에서 연구를 해야하지만 최근 발표되는 LLM들은 closed-source 모델인 경우가 많아 제약이 있습니다.

## 모델 구조

![](/assets/img/llm/alpaca.png)

먼저, 사람이 직접 작성한 seed instruction set 175개를 수집했습니다. 그리고 이를 GPT-3.5에 프롬프트로 입력하여 지시문-출력 데이터를 생성하도록 했습니다. 결과적으로 OpenAI API 호출 비용 약 500달러로 52,000개의 데이터셋을 생성해 냈습니다. 사람이 같은 양의 데이터를 만들 때 드는 비용보다 훨씬 저렴한 비용으로 학습용 데이터셋을 생성한 것입니다. 그 다음, 생성된 52,000개의 데이터셋을 LLaMA 7B 모델에 학습시켜 instruction-tuning을 진행했습니다.

## 모델 성능

![](/assets/img/llm/alpaca_ex.png)

사람이 직접 Alpaca 모델의 성능을 평가했을 때, GPT-3.5와 비슷한 품질의 답변을 생성했습니다.