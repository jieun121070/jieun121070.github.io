---
title: "[Paper Review] Alpaca: A Strong, Replicable Instruction-Following Model"
date: 2024-4-21
author: jieun
math: True
categories: [Language-Model]
tags: [LLM, sLLM, Llama, Alpaca]
typora-root-url: ..
---

오늘 소개할 [**Alpaca**](https://crfm.stanford.edu/2023/03/13/alpaca.html)는 Stanford에서 LLaMA 7B를 기반으로 만든 파생 모델입니다. LLaMA 자체는 단순 언어 모델인데, LLaMA에 instruction tuning을 거쳐 나온 모델이 바로 Alpaca입니다. instruction tuning은 모델이 사용자의 지시문을 이해하고, 그 지시에 맞춰 작업을 수행하도록 학습시키는 과정을 의미하는데요. instruction tuning을 위해서는 아래와 같이 지시문과 출력으로 이루어진 데이터가 필요합니다. 

> Instruction: Translate the sentence "I love machine learning" to French.  
> Output: J'aime l'apprentissage automatique.

Alpaca는 이러한 instruction data를 GPT-3.5 API를 사용해 아주 저렴하게 만드는 방법을 보여주었다는 점에서 큰 의미를 갖는 모델입니다. Alpaca의 모델 구조와 instruction data를 만든 과정을 좀 더 자세히 살펴보겠습니다.

## 모델 구조

![](/assets/img/llm/alpaca.png)