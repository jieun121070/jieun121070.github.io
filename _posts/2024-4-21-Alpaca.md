---
title: "[Paper Review] Alpaca: A Strong, Replicable Instruction-Following Model"
date: 2024-4-21
author: jieun
math: True
categories: [Language-Model]
tags: [LLM, sLLM, Llama, Alpaca]
typora-root-url: ..
---

오늘 소개할 [**Alpaca**](https://crfm.stanford.edu/2023/03/13/alpaca.html)는 Stanford에서 LLaMA 7B를 기반으로 만든 파생 모델입니다. LLaMA 자체는 단순 언어 모델인데, LLaMA에 instruction tuning을 거쳐 나온 모델이 바로 Alpaca입니다. instruction tuning은 모델이 사용자의 지시문을 이해하고, 그 지시에 맞춰 작업을 수행하도록 학습시키는 과정을 의미하는데요. instruction tuning을 위해서는 아래와 같이 지시문과 출력으로 이루어진 데이터가 필요합니다. 

> Instruction: Translate the sentence "I love machine learning" to French.  
> Output: J'aime l'apprentissage automatique.

Alpaca는 이러한 instruction data를 GPT-3.5 API를 사용해 아주 저렴하게 만드는 방법을 보여주었다는 점에서 큰 의미를 갖는 모델입니다. Alpaca의 모델 구조와 instruction data를 만든 과정을 좀 더 자세히 살펴보겠습니다.

## 모델 구조

![](/assets/img/llm/alpaca.png)

먼저, 사람이 직접 작성한 seed instruction set 175개를 수집했습니다. 그리고 이를 GPT-3.5에 프롬프트로 입력하여 지시문-출력 데이터를 생성하도록 했습니다. 결과적으로 OpenAI API 호출 비용 약 500달러로 52,000개의 데이터셋을 생성해 냈습니다. 사람이 같은 양의 데이터를 만들 때 드는 비용보다 훨씬 저렴한 비용으로 학습용 데이터셋을 생성한 것입니다. 그 다음, 생성된 52,000개의 데이터셋을 LLaMA 7B 모델에 학습시켜 instruction-tuning을 진행했습니다.

### Self-Instruct

데이터셋을 생성한 과정을 단계 별로 좀 더 자세히 살펴보면 아래와 같습니다.

| 단계                         | 목적 & 작업 내용                                             |
| ---------------------------- | ------------------------------------------------------------ |
| 1. seed instruction set 수집 | 사람이 100~200개 내외의 다양한 task instruction을 직접 작성해 '초기 작업 세트'를 만듭니다. |
| 2. instruction 생성          | GPT-3.5를 호출해 "이전과 다른 형태/주제/난이도의 새 task instruction $k$개를 작성해줘"라고 지시합니다. |
| 3. instruction 검증·분류     | 자동 스크립트로 ①명령문 형식 여부, ②금지 주제(증오/성인/정치적 선동 등) 여부, ③중복/반복 여부를 걸러내고, 분류(classification) vs. 생성(generation) 과제로 태깅합니다. |
| 4. 인스턴스 생성             | 남은 지시문마다 (입력, 답변) 예시를 만듭니다.<br />- `Input-first`: LLM에 "입력 예시 → 정답(출력)을 작성" 지시<br />- `Output-first`: 먼저 출력 여러 개를 샘플링한 뒤 적절한 입력을 역추론 |
| 5. 필터링 & 중복 제거        | - 품질 필터: 길이/금지어/불완전 문장 제거<br />- Semantic similarity 체크로 기존 데이터와 너무 비슷한 항목 제거 |

## 모델 성능

![](/assets/img/llm/alpaca_ex.png)

사람이 직접 Alpaca 모델의 성능을 평가했을 때, GPT-3.5와 비슷한 품질의 답변을 생성했습니다.