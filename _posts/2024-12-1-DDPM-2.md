---
title: "[Paper Review] DDPM: Denoising Diffusion Probabilistic Models (2)"
date: 2024-11-2
author: jieun
math: True
categories: [Vision]
tags: [DDPM, Diffusion]
typora-root-url: ..
---

이번 포스트에서는 [지난 포스트](https://jieun121070.github.io/posts/DDPM/)에 이어 [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239)에 대해 좀 더 자세히 알아보겠습니다.

## 1. 모델 학습과 이미지 생성

### 모델 학습

지난 포스트에서 설명한 바와 같이, DDPM은 데이터에 노이즈를 점진적으로 확산시킨 다음, 그 과정을 거꾸로 학습합니다. timestep $t$에 따라 데이터에 노이즈를 더하는 정방향 과정은 아래와 같이 정의합니다. 

$$x_t=\sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}\varepsilon_t,
\qquad \varepsilon_t \sim \mathcal N(\mathbf 0,\mathbf I)$$

$$\begin{align}
\text{Var}(x_t) &= \text{Var}(\sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}\varepsilon_t) \\
&= \text{Var}(\sqrt{1-\beta_t}x_{t-1})+\text{Var}(\sqrt{\beta_t}\varepsilon_t) \\
&= (1-\beta_t)\text{Var}(x_{t-1})+\beta_t\text{Var}(\varepsilon_t) \\
&= (1-\beta_t)\text{Var}(x_{t-1})+\beta_t
\end{align}$$

정방향 한 step이 지나면, 분산이 $(1-\beta_t)$배만큼 남고, 새 노이즈가 $\beta_t$만큼 더해집니다. $\beta_t$가 작을수록 이전 step 분산이 많이 남습니다.

$$q(x_t⁣∣⁣x_{t−1}) = \mathcal{N}(x_t\;;\;\sqrt{1-\beta_t}x_{t-1},\;\beta_tI)$$

더해진 노이즈를 예측하는 역방향 과정은 아래와 같이 정의합니다.

$$x_{t-1} = \frac{1}{\sqrt{1-\beta_t}} \Bigl(x_t-\frac{\beta_t}{\sqrt{\bar\alpha_t}} \hat\varepsilon_\theta(x_t,t) \Bigr)+\sqrt{\tilde\beta_t}z$$

$$p_\theta(x_{t-1}⁣∣⁣x_t, x_0) = \mathcal{N}(x_{t-1}\;;\;\tilde{\mu_t}(x_t, x_0),\; \tilde{\beta_t}I)$$

모델 학습 과정을 자세히 살펴보면 아래와 같습니다.

- `Step 1` timestep $t$를 뽑고, 원본 이미지 $x_0$에 $t$시점까지 정방향으로 노이즈를 누적해서 더한 이미지 $x_t$를 구합니다. 앞서 설명한 닫힘 성질 덕분에 원본 이미지 $x_0$에 매 시점 노이즈를 누적해서 더하는 과정을 거치지 않고,  $x_t$를 한 번에 샘플링할 수 있습니다. $\beta$-스케줄은 일반적으로 선형(1e-4 → 0.02) 또는 코사인 스케줄을 많이 사용합니다. 작은 $\beta$부터 시작해 서서히 노이즈를 키워야 역방향 학습이 안정적으로 이루어집니다.

$$x_t=\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\varepsilon,
\qquad \varepsilon \sim \mathcal N(\mathbf 0,\mathbf I),\;\bar{\alpha}_t = \prod_{s=1}^{t} (1 - \beta_s)$$

- `Step 2` **U-Net**에 $x_t$와 시점 $t$를 입력해 $x_t$에 더해진 **노이즈 $\varepsilon$를 예측**합니다. 이 때, $t$는 `sinusoidal position embedding` 후에 MLP를 거친 다음 `ResidualBlock`에 `FiLM` 방식으로 주입합니다. 아래 그림에서 실선 화살표가 UNet($p_\theta$) 추정 경로입니다.

![](/assets/img/diffusion/ddpm.png)

- `Step 3` 이미 알고 있는 정답 노이즈 $\varepsilon$와 U-Net을 통해 구한 노이즈의 예측값 $\hat\varepsilon_\theta$로 $\varepsilon$-MSE Loss를 계산하고 Adam optimizer로 파라미터를 업데이트합니다. $\varepsilon$-MSE Loss는 timestep별 $\sigma^2$ 가중 Denoising Score Matching(DSM) loss와 동치입니다. 따라서 둘 중 어떤 loss를 사용하든 같은 $\theta$에 수렴하게 됩니다. 다시 말해, **$\varepsilon$-MSE를 최소화하면 score를 정확하게 예측할 수 있게 됩니다.**

$$\mathcal L_{\text{simple}}   = \mathbb E_{t,\,x_0,\,\varepsilon}     \bigl[        \,\bigl\|\,           \varepsilon -           \hat\varepsilon_{\theta}(x_t,\,t)        \bigr\|_2^2     \bigr]$$

`Step 3`에서 설명한 score는 다음과 같이 정의됩니다. 어떤 시점 $t$ (또는 노이즈 $\sigma_t$)에서의 확률 밀도 함수 $p_t(x_t)$가 주어졌을 때, 그 log-likelihood를 데이터 $x_t$에 대해 편미분한 벡터입니다. 이는 log-likelihood를 빠르게 높이는 방향을 의미합니다.

$$s(x)=\nabla_{x}\,\log p(x)$$

이미지 생성 모델 관점에서 확률 밀도 함수 $p_t(x_t)$의 log-likelihood는 모델이 생성한 이미지 $x_t$가 얼마나 있을 법한 이미지인지를 나타낸다고 볼 수 있습니다. score는 모델이 자연스러운 이미지를 만들어내기 위한 방향입니다. 가우시안의 score 공식은 아래와 같습니다.

$$s(x)=\nabla_{x}\,\log \mathcal N\!\bigl(x;\,\mu,\Sigma\bigr)
   \;=\;
   -\,\Sigma^{-1}\,\bigl(x-\mu\bigr)$$

특히 DDPM처럼 공분산 행렬이 스칼라와 단위 행렬 $I$의 곱으로 표현되는 등방 가우시안($\Sigma=\sigma^2I$)인 경우, 아래와 같은 관계가 성립합니다. 따라서 모델이 $\varepsilon$를 잘 맞추면 score 역시 간단한 연산으로 얻을 수 있습니다.

$$s(x)=-\frac{x-\mu}{\sigma^2}=-\frac{\varepsilon}{\sigma}$$

### 이미지 생성(샘플링)

- `Step 1` $x_T$를 초기화합니다. $x_T \sim \mathcal N(\mathbf 0,\mathbf I)$
- `Step 2` **U-Net**으로 $\varepsilon$를 예측합니다. 필요 시 score로 변환합니다. 앞서 설명한 것처럼 $\varepsilon$와 score는 아래와 같은 선형 관계입니다.

$$\hat{s}=−\hat{\varepsilon}/\sigma_{t}$$

- `Step 3` `Step 2`에서 구한 $\hat\varepsilon_\theta$를 샘플러에 입력해서 매 역방향 step $x_t \rightarrow x_{t-1}$에서 $x_{t-1}$을 계산합니다. 이 때, $x_t$가 score 방향으로 조금씩 수정되고, 그 누적 결과로 노이즈 $x_T$가 데이터 $x_0$로 복원됩니다. 

$$
x_{t-1} =
\frac{1}{\sqrt{1-\beta_t}}\,
\Bigl(
    x_t - \frac{\beta_t}{\sqrt{\bar\alpha_t}}\,
    \hat\varepsilon_\theta(x_t,\,t)
\Bigr)
+ \sqrt{\tilde\beta_t}\,z,
\qquad
z \sim \mathcal N(0,I),
\;
\tilde\beta_t =
\frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\,\beta_t.
$$

## 2. 모델 구조

![](/assets/img/diffusion/unet.png)
_U-Net architecture_

앞서 설명한 바와 같이 DDPM은 노이즈 $\varepsilon$를 예측할 때 **U-Net**을 사용합니다. DDPM에서는 기존 U-Net에서 **Residual Block**과 **Multi-Head Attention**을 추가해 사용했습니다. activation function으로는 **SiLU(Swish)**를 사용했습니다. [이곳](https://nn.labml.ai/diffusion/ddpm/unet.html)에서 DDPM에 사용된 U-Net 코드를 확인할 수 있습니다.

### Encoder (Contracting Path)

- **Downsampling 및 feature 추출:** 노이즈가 포함된 이미지 $x_t$와 sinusoidal position embedding을 거친 현재 timestep 정보 $t$를 입력받습니다. 여러 층의 Convolutional Layer와 Downsampling Layer를 통과하며 이미지의 공간적 해상도는 점진적으로 줄어들고, 대신 feature map의 채널 수는 증가합니다. 이 과정에서 이미지의 추상적인 feature가 추출됩니다.

### Decoder (Expanding Path)

- **Upsampling  및 이미지 재구성:** Encoder의 마지막 단계에서 얻은 가장 압축된 feature map을 입력받아, Upsampling Layers와 Convolutional Layer를 통해 점진적으로 해상도를 늘려나갑니다. 이 과정에서 채널 수는 다시 줄어들며, 최종적으로 원본 이미지와 동일한 해상도의 노이즈 예측값 $\hat\varepsilon_\theta$을 출력합니다.
- **Skip Connection:** U-Net의 가장 중요한 특징 중 하나로, Encoder의 각 단계에서 Decoder의 상응하는 단계로 직접 연결되는 통로입니다. 위 U-Net architecture 그림에서 회색 화살표에 해당합니다. 이 Skip Connection은 Encoder에서 손실될 수 있는, 이미지 가장자리나 세부 질감같은 고해상도의 세밀한 공간 정보를 Decoder로 바로 전달합니다. Skip Connection 구조 덕분에 모든 스케일에서의 정보를 종합하여 노이즈 $\varepsilon$을 정확하게 예측할 수 있고, 결과적으로 고품질 이미지 복원을 가능해 집니다.

### Residual Block

- Encoder와 Decoder의 각 단계에는 [Residual Block](https://jieun121070.github.io/posts/Resnet/)이 포함됩니다. Residual Block은 입력에 여러 Convolutional Layer를 적용한 후 원본 입력을 더해주는 구조 $F(x)+x$로, 네트워크가 깊어져도 vanishing gradients 문제를 완화하고 정보 흐름을 개선하여 안정적인 학습을 돕습니다. 이는 DDPM이 복잡한 노이즈 패턴과 다양한 스케일의 이미지 feature를 학습하는 데 필수적입니다.

### Multi-Head Attention

- **전역적 feature 포착:** U-Net의 중간 해상도 단계에는 Multi-Head Attention이 사용됩니다. Convolutional Layer가 주로 지역적(local) feature를 포착하는 데 강한 반면, 이미지의 전체적인 구성 및 맥락, 객체들의 배치나 배경과 객체의 관계처럼 넓은 범위에 걸쳐 있는 전역적(global) feature를 포착하는 데는 한계가 있기 때문에 도입되었습니다.

- **이미지 품질 및 일관성 향상:** Multi-Head Attention은 이미지의 다양한 영역 간의 복잡한 관계를 모델링하여, 생성되는 이미지의 일관성과 사실감을 높이는 데 기여합니다.
- **시간 정보 통합:** timestep 정보 $t$를 나타내는 time embedding vector는 Multi-Head Attention block에도 입력됩니다. time embedding vector를 입력하는 대표적인 방식은 Query, Key, Value 각각에 time embedding vector를 더하거나 연결하는 것입니다. 이를 통해 모델이 각 노이즈 레벨에 맞는 적절한 전역적 feature를 학습할 수 있게 됩니다.

## Reference

- [확률편미분방정식과 인공지능](https://horizon.kias.re.kr/25133/)
