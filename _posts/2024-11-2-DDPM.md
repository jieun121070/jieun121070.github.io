---
title: "[Paper Review] DDPM: Denoising Diffusion Probabilistic Models"
date: 2024-11-2
author: jieun
math: True
categories: [Vision]
tags: [DDPM]
typora-root-url: ..
---

[Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239)은 diffusion 확률 모델을 이용해 고품질의 이미지를 생성하는 모델입니다. DDPM의 핵심 아이디어는 timestep $t$에 따라 데이터에 노이즈를 점차 확산(diffusion)시킨 다음, 그 과정을 거꾸로 학습해서 데이터를 생성하는 것입니다.

## 1. Markov Chain

모델 구조에 대해 자세히 살펴보기 전에, 먼저 Markov Chain에 대해 알아보겠습니다. **Markov Property**를 만족하는 시퀀스를 **Markov Chain**이라고 합니다. Markov Property는 과거와 현재 상태가 주어졌을 때, **미래 상태 $X_t$의 조건부 확률 분포가** 과거 상태들로부터 독립적으로 **현재 상태 $X_{t-1}$에 의해서만 결정된다**는 것을 뜻합니다.

$$\Pr\!\bigl(X_t = x_t \,\big|\, X_0 = x_0,\dots,X_{t-1} = x_{t-1}\bigr)
\;=\;
\Pr\!\bigl(X_t = x_t \,\big|\, X_{t-1} = x_{t-1}\bigr)
,\quad\forall\,t\ge 1.$$

뒤에서 자세히 설명할 예정이지만, DDPM은 원본 이미지 $x_0$에 노이즈를 순차적으로 누적해서 더합니다. $x_{t-1}$에 노이즈를 더해 $x_t$를 만드는 과정을 반복하는 것입니다. 따라서 시퀀스 $x_0,..., x_T$는 Markov Chain이 됩니다.

$$x_t=\sqrt{1-\beta_t}\,x_{t-1}+\sqrt{\beta_t}\,\varepsilon,\;\varepsilon \sim \mathcal N(\mathbf 0,\mathbf I).$$

노이즈로는 **가우시안 노이즈**가 사용됩니다. 저자들이 가우시안 노이즈를 선택한 이유는 계산 편의성 때문입니다. 조건부 관점에서 $x_{t-1}$는 상수 취급되고, $\varepsilon$는 표준 가우시안 벡터입니다. 가우시안은 선형 변환 후에도 가우시안이므로, $\varepsilon \sim \mathcal N(\mathbf 0,\mathbf I)$에 $\sqrt{\beta_t}$를 곱해도 가우시안이 유지됩니다. 따라서 조건부 분포 $q(x_t | x_{t-1})$도 평균이 $\sqrt{1-\beta_t}\,x_{t-1}$이고, 공분산이 $\beta_t \mathbf I$인 가우시안 분포를 따르게 되는 것입니다. 이러한 성질을 닫힘 성질이라고 합니다.

$$q\!\bigl(x_t \,\big|\, x_{t-1}\bigr) = \mathcal N\!\Bigl(\sqrt{1-\beta_t}\,x_{t-1},\;\beta_t \mathbf I \Bigr)$$

이 닫힘 성질 덕분에 원본 이미지 $x_0$에 $t$ 시점까지 노이즈를 누적해서 더한 이미지 $x_t$를 한 번에 구할 수 있습니다.

$$x_t=\sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\varepsilon,
\;
\bar{\alpha}_t = \prod_{s=1}^{t} (1 - \beta_s)$$

## 2. 모델 구조

![](/assets/img/diffusion/ddpm.png)
