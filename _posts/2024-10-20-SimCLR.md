---
title: "[Paper Review] SimCLR: A Simple Framework for Contrastive Learning of Visual Representations"
date: 2024-10-20
author: jieun
math: True
categories: [Vision]
tags: [SimCLR, Contrastive-Learning]
typora-root-url: ..
---

Self-supervised learning은 데이터 자체로부터 파생된 가짜 라벨(proxy label)을 예측하는 task를 수행해 데이터를 효과적으로 표현하는 embedding을 학습하는 방법입니다. 학습 방식은 크게 세 가지로 나누어 볼 수 있습니다.

![](/assets/img/diffusion/ssl.PNG)

- `Context Based` 이미지 내의 작고 구체적인 정보를 가린 다음 정답을 스스로 생성합니다. 이미지를 회색으로 바꾸거나, 이미지를 패치로 나누어 섞어서 가짜 라벨을 만듭니다.
- `Contrastive learning` 같은 이미지 쌍의 거리는 가깝게, 다른 이미지 쌍의 거리는 멀어지도록 embedding을 학습합니다.
- `Masked Image Modeling` 큰 패치 전체를 무작위로 최대 80%까지 가리고 복원합니다.

오늘 소개할 SimCLR은 이 중에서도 Contrastive learning에 속하는 모델입니다. SimCLR 이후에 등장한 Vision 분야 Contrastive learning 모델들은 SimCLR의 모델 구조를 기반으로 발전한 경우가 많습니다. 예를 들어, SimCLR에서 이미지 간 유사도 계산 과정을 이미지와 텍스트 간 유사도 계산 과정으로 바꾼 것이 2020년 OpenAI에서 발표한 CLIP입니다. 그만큼 영향력이 크고, 이미지의 핵심 feature를 학습하는 강력한 방법을 제시한 논문인데요. 모델 구조와 그 성능에 대해 자세히 알아보겠습니다.

## 1. 모델 구조



![](/assets/img/diffusion/SimCLR.gif)